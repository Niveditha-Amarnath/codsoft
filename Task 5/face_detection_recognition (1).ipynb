{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "guQiyDg-TK6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n"
      ],
      "metadata": {
        "id": "_JJm3YGWTLLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cascade_face = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') #Load the cascade"
      ],
      "metadata": {
        "id": "75hVBVHWVo_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)"
      ],
      "metadata": {
        "id": "7ORlFsaZaLq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow for displaying images in Colab\n",
        "\n",
        "# Initialize video capture\n",
        "cap = cv2.VideoCapture('video_file.mp4')  # Replace with your video source\n",
        "\n",
        "# Check if video capture was successful\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Video capture could not be opened.\")\n",
        "    exit()\n",
        "\n",
        "# Load the face cascade classifier\n",
        "cascade_face = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')  # Replace with your cascade file\n",
        "\n",
        "while True:\n",
        "    ret, img = cap.read()\n",
        "\n",
        "    # Check if frame was read successfully\n",
        "    if not ret:\n",
        "        print(\"Error: Frame could not be read.\")\n",
        "        break\n",
        "\n",
        "    # Convert the frame to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces in the grayscale frame\n",
        "    faces = cascade_face.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "    # Rest of your face detection code here...\n",
        "\n",
        "    # Display the frame with detected faces using cv2_imshow\n",
        "    cv2_imshow(img)\n",
        "\n",
        "    # Break the loop if 'q' key is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the video capture and close any open windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "D_cKRy6JaVpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HnB3WJPZaYQk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}